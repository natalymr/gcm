{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "import string\n",
    "from typing import Dict, List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_tokens_and_tags(sentence: str) -> List[Tuple[str, str]]:\n",
    "    sentence_without_punctuation = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(sentence_without_punctuation)\n",
    "    return nltk.pos_tag(tokens)\n",
    "\n",
    "def get_sentence_tags(sentence: str) -> List[str]:\n",
    "    tokens: List[Tuple[str, str]] = get_sentence_tokens_and_tags(sentence)\n",
    "#     print(tokens)\n",
    "    only_tags: List[str] = []\n",
    "    \n",
    "    for _, tag in tokens:\n",
    "        only_tags.append(tag)\n",
    "#     print(only_tags)\n",
    "    return only_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'NN', 'VBD', 'VBN', 'IN', 'NN', 'TO', 'VB', 'NN', 'NN']\n",
      "['NNS', 'VBG', 'IN', 'NN', 'NN', 'NNS', 'IN', 'NNP', 'NNP', 'JJ', 'NN', 'NN', 'WRB', 'VBG', 'NNS', 'IN', 'NNP', 'NN', 'NNS', 'IN', 'NNP', 'NN', 'MD', 'VB', 'VBN', 'RB', 'IN', 'PRP', 'VBP', 'VBN', 'IN', 'NN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "# test for tagging \n",
    "\n",
    "print(get_sentence_tags(\"This commit was manufactured by cvs2svn to create branch 'lesya'\"))\n",
    "print(get_sentence_tags(\"fixes: sorting of resource bundle properties in UI Designer; extra method invocation when finding classes in Debugger; resource bundles in UI designer can be used even if they are located in non-default package\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages = 16923\n"
     ]
    }
   ],
   "source": [
    "# get dataset for actual messages\n",
    "data_file = \"/Users/natalia.murycheva/Documents/code2seq/result.aurora.correct.csv\"\n",
    "commit_vs_message: Dict[str, str] = {}\n",
    "commit_vs_tags: Dict[str, List[str]] = {}\n",
    "commit_index = 0\n",
    "actual_message_index = 3\n",
    "i = 0   \n",
    "\n",
    "with open(data_file, newline='') as f:\n",
    "    reader = csv.reader(f, delimiter='^')\n",
    "    is_first = True\n",
    "    last_commit = \"\"\n",
    "    \n",
    "    for row in reader:\n",
    "        if is_first:\n",
    "            last_commit = row[commit_index]\n",
    "            is_first = False\n",
    "            \n",
    "        if row[commit_index] != \"\":\n",
    "            last_commit = row[commit_index]\n",
    "        \n",
    "            if row[actual_message_index] != \"\":\n",
    "                commit_vs_message[last_commit] = row[actual_message_index]\n",
    "                tags = get_sentence_tags(row[actual_message_index])\n",
    "                if tags:                    \n",
    "                    i += 1\n",
    "                    commit_vs_tags[last_commit] = tags\n",
    "                    \n",
    "print(f\"Number of messages = {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16923"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commit_vs_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dataset: List[List[str]] = []\n",
    "    \n",
    "for key, value in commit_vs_tags.items():\n",
    "    tags_dataset.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NN'], ['NN'], ['NNS'], ['NN'], ['NN'], ['DT', 'NN', 'VBD', 'VBN', 'IN', 'NN', 'TO', 'VB', 'NN', 'NN'], ['NN'], ['NN'], ['NN'], ['NN']]\n"
     ]
    }
   ],
   "source": [
    "print(tags_dataset[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "n = 3\n",
    "train, padded = padded_everygram_pipeline(n, tags_dataset)\n",
    "model = MLE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NNS',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NNS'), ('NNS', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NNS'), ('<s>', 'NNS', '</s>'), ('NNS', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('DT',), ('NN',), ('VBD',), ('VBN',), ('IN',), ('NN',), ('TO',), ('VB',), ('NN',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'DT'), ('DT', 'NN'), ('NN', 'VBD'), ('VBD', 'VBN'), ('VBN', 'IN'), ('IN', 'NN'), ('NN', 'TO'), ('TO', 'VB'), ('VB', 'NN'), ('NN', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'DT'), ('<s>', 'DT', 'NN'), ('DT', 'NN', 'VBD'), ('NN', 'VBD', 'VBN'), ('VBD', 'VBN', 'IN'), ('VBN', 'IN', 'NN'), ('IN', 'NN', 'TO'), ('NN', 'TO', 'VB'), ('TO', 'VB', 'NN'), ('VB', 'NN', 'NN'), ('NN', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n",
      "[('<s>',), ('<s>',), ('NN',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'NN'), ('NN', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'NN'), ('<s>', 'NN', '</s>'), ('NN', '</s>', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "for i, a in enumerate(train):\n",
    "    print(list(a))\n",
    "    if i > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40547703180212014\n",
      "0.0525092936802974\n",
      "0.2515923566878981\n"
     ]
    }
   ],
   "source": [
    "# model.score('is', 'language'.split())  # P('is'|'language')\n",
    "# model.score('never', 'language is'.split())  # P('never'|'language is')\n",
    "\n",
    "print(model.score('NN', 'IN'.split()))\n",
    "print(model.score('VBN', 'VBD'.split()))\n",
    "print(model.score('VBN', 'NN VBD'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16873\n",
      "33812\n",
      "33812\n"
     ]
    }
   ],
   "source": [
    "print(model.counts['NN'])\n",
    "print(model.counts['<s>'])\n",
    "print(model.counts['</s>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter predicted tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "commit_vs_predicted_message: Dict[str, List[List[Tuple[str, str]]]] = collections.defaultdict(list)\n",
    "    \n",
    "commit_index = 0\n",
    "predicted_message_index = 5\n",
    "    \n",
    "\n",
    "code2seq_commits_all = set()\n",
    "with open(data_file, newline='') as f:\n",
    "    reader = csv.reader(f, delimiter='^')\n",
    "    is_first = True\n",
    "    last_commit = \"\"\n",
    "    \n",
    "    for row in reader:\n",
    "        if is_first:\n",
    "            last_commit = row[commit_index]\n",
    "            code2seq_commits_all.add(last_commit)\n",
    "            is_first = False\n",
    "            \n",
    "        if row[commit_index] != \"\":\n",
    "            last_commit = row[commit_index]\n",
    "        \n",
    "        predicted_message = row[predicted_message_index]\n",
    "        if predicted_message != \"\":\n",
    "            tokens_and_tags = get_sentence_tokens_and_tags(predicted_message)\n",
    "            if tokens_and_tags:\n",
    "                code2seq_commits_all.add(last_commit)\n",
    "                commit_vs_predicted_message[last_commit].append(tokens_and_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19036"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commit_vs_predicted_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('first', 'RB'), ('replace', 'VB'), ('statement', 'NN'), ('expression', 'NN'), ('implementation', 'NN'), ('used', 'VBN'), ('to', 'TO'), ('enable', 'VB'), ('the', 'DT'), ('testing', 'NN')], [('first', 'RB'), ('replace', 'VB'), ('statement', 'NN'), ('expression', 'NN'), ('implementation', 'NN'), ('used', 'VBN'), ('to', 'TO'), ('enable', 'VB'), ('the', 'DT'), ('testing', 'NN')]]\n",
      "[[('add', 'VB'), ('support', 'NN'), ('for', 'IN'), ('different', 'JJ'), ('license', 'NN'), ('managers', 'NNS'), ('ui', 'VBP'), ('bug', 'NN')]]\n",
      "[[('fixed', 'VBN'), ('issue', 'NN'), ('with', 'IN'), ('not', 'RB'), ('external', 'JJ'), ('up', 'RP'), ('in', 'IN'), ('xml', 'NN')], [('added', 'VBD'), ('css', 'NN'), ('xhtml', 'NNP'), ('binding', 'VBG'), ('second', 'JJ'), ('cut', 'NN'), ('specified', 'VBN'), ('if', 'IN')], [('added', 'JJ'), ('usage', 'NN'), ('view', 'NN'), ('to', 'TO'), ('openapi', 'VB'), ('bundle', 'JJ'), ('been', 'VBN'), ('check', 'VB'), ('start', 'NN')]]\n",
      "[[('fixes', 'NNS'), ('sorting', 'VBG'), ('of', 'IN'), ('resource', 'NN'), ('bundle', 'NN'), ('properties', 'NNS'), ('for', 'IN'), ('ui', 'JJ'), ('designer', 'NN'), ('extra', 'JJ')], [('fixed', 'VBN'), ('read', 'JJ'), ('access', 'NN'), ('allowed', 'VBN'), ('assertion', 'NN'), ('access', 'NN'), ('unmatched', 'VBD'), ('for', 'IN')], [('fixes', 'NNS'), ('sorting', 'VBG'), ('of', 'IN'), ('resource', 'NN'), ('bundle', 'NN'), ('properties', 'NNS'), ('in', 'IN'), ('ui', 'JJ'), ('designer', 'NN'), ('extra', 'JJ')], [('sh', 'NN'), ('mem', 'NN'), ('for', 'IN'), ('j', 'NN'), ('num', 'NN'), ('ee', 'NN'), ('bug', 'NN'), ('dialog', 'NN')], [('fixes', 'NNS'), ('sorting', 'VBG'), ('of', 'IN'), ('resource', 'NN'), ('bundle', 'NN'), ('properties', 'NNS'), ('in', 'IN'), ('ui', 'JJ'), ('designer', 'NN'), ('extra', 'JJ')], [('fixes', 'NNS'), ('sorting', 'VBG'), ('of', 'IN'), ('resource', 'NN'), ('bundle', 'NN'), ('properties', 'NNS'), ('for', 'IN'), ('ui', 'JJ'), ('designer', 'NN'), ('extra', 'JJ')], [('fixes', 'NNS'), ('in', 'IN'), ('tests', 'NNS'), ('tei', 'NNS'), ('and', 'CC'), ('tld', 'JJ'), ('get', 'NN'), ('file', 'NN')], [('scr', 'NN'), ('num', 'CC'), ('helper', 'NN'), ('should', 'MD'), ('get', 'VB'), ('start', 'VB')], [('fixes', 'NNS'), ('in', 'IN'), ('tests', 'NNS'), ('and', 'CC'), ('tld', 'JJ'), ('get', 'NN'), ('file', 'NN')]]\n",
      "[[('tabs', 'NNS'), ('refactored', 'VBD'), ('to', 'TO'), ('outer', 'VB'), ('space', 'NN'), ('custom', 'NN'), ('section', 'NN'), ('evaluation', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for key, value in commit_vs_predicted_message.items():\n",
    "    j += 1\n",
    "    if j > 5:\n",
    "        break\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba(tag: str, resulted_token_and_tags: List[Tuple[str, str]]) -> float:\n",
    "    global model\n",
    "    if len(resulted_token_and_tags) >= 2:\n",
    "        prev_tag = resulted_token_and_tags[-1][1]\n",
    "        prev_prev_tag = resulted_token_and_tags[-2][1]\n",
    "\n",
    "        bigram_proba = model.score(tag, prev_tag)\n",
    "        threegram_proba = model.score(tag, [prev_prev_tag, prev_tag])\n",
    "\n",
    "        return bigram_proba + threegram_proba\n",
    "    elif len(resulted_token_and_tags) == 1:\n",
    "        prev_tag = resulted_token_and_tags[-1][1]\n",
    "        return model.score(tag, prev_tag)\n",
    "    else:\n",
    "        return 1.\n",
    "\n",
    "    \n",
    "def delete_serial_same_tokens(tokens_and_tags: List[Tuple[str, str]]) -> List[Tuple[str, str]]:\n",
    "    results_tokens = []\n",
    "\n",
    "    prev = tokens_and_tags[0][0]\n",
    "    results_tokens.append(tokens_and_tags[0])\n",
    "    for token, tag in tokens_and_tags[1:]:\n",
    "        if token != prev:\n",
    "            results_tokens.append((token, tag))\n",
    "            prev = token\n",
    "    return results_tokens\n",
    "\n",
    "def filter_tags_by_probability(tokens_and_tags: List[Tuple[str, str]], threshold=0.20) -> str:\n",
    "    resulted_tuples: List[Tuple[str, str]] = []\n",
    "    tokens_and_tags_no_d = delete_serial_same_tokens(tokens_and_tags)\n",
    "    size = len(tokens_and_tags_no_d)\n",
    "    \n",
    "    if size > 1:\n",
    "        mid = size // 2 \n",
    "        for i in range(mid):\n",
    "            resulted_tuples.append(tokens_and_tags_no_d[i])\n",
    "\n",
    "        for token, tag in tokens_and_tags_no_d[mid:]:\n",
    "            proba = get_proba(tag, resulted_tuples)\n",
    "            if proba > threshold:\n",
    "                resulted_tuples.append((token, tag))\n",
    "        return [token for token, tag in resulted_tuples]\n",
    "    else:\n",
    "        return [token for token, tag in tokens_and_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19036\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for commit in commit_vs_predicted_message.keys():\n",
    "    if commit_vs_predicted_message[commit]:\n",
    "        j += 1\n",
    "\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_predicted_messages: Dict[str, List[List[str]]] = collections.defaultdict(list)\n",
    "\n",
    "for commit in commit_vs_predicted_message.keys():    \n",
    "    all_messages = commit_vs_predicted_message[commit]\n",
    "    for message in all_messages:\n",
    "        filtered_message = filter_tags_by_probability(message)\n",
    "        filtered_predicted_messages[commit].append(filtered_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_predicted_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19036"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commit_vs_predicted_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all messages in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = add default hint\n"
     ]
    }
   ],
   "source": [
    "def get_common_message_prefix(messages: List[List[str]]) -> Optional[List[str]]:\n",
    "    result_tokens = []\n",
    "    max_size = max([len(message) for message in messages])\n",
    "    \n",
    "    for i in range(max_size):\n",
    "        tokens_slice = []\n",
    "        for message in messages:\n",
    "            try:\n",
    "                tokens_slice.append(message[i])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        counter = Counter(tokens_slice)\n",
    "        result_tokens.append(max(counter, key=counter.get))\n",
    "\n",
    "        if result_tokens in messages:\n",
    "            return result_tokens\n",
    "    return None\n",
    "\n",
    "def leave_only_one_message_per_commit(messages: List[List[str]]) -> str:\n",
    "    messages_str = [\" \".join([token for token in message]) for message in messages]\n",
    "    unique_messages = set(messages_str)\n",
    "    if len(messages_str) > len(unique_messages):\n",
    "        counter = Counter(messages_str)\n",
    "        max_message = max(counter, key=counter.get)\n",
    "        number_of_dublicates = counter[max_message]\n",
    "        if number_of_dublicates > 1:\n",
    "            return max_message\n",
    "    \n",
    "    common_message: List[str] = get_common_message_prefix(messages)\n",
    "    if common_message:\n",
    "        return \" \".join(common_message)\n",
    " \n",
    "    return \"massive changes\"\n",
    "        \n",
    "# tests\n",
    "a = [['fixed', 'another', 'issue', 'with', 'xml'],\n",
    "    ['scr', 'num', 'get', 'file'],\n",
    "    ['add', 'source', 'specification'],\n",
    "    ['fixed', 'another', 'issue', 'with', 'xml', 'url'],\n",
    "    ['add', 'children', 'profile'],\n",
    "    ['add', 'default', 'hint'],\n",
    "    ['add', 'default'],\n",
    "    ['add', 'default', 'profile', 'hint', 'completion'],\n",
    "    ['add', 'default', 'hint']]\n",
    "print(f\"max = {leave_only_one_message_per_commit(a)}\")\n",
    "# for commit in filtered_predicted_messages.keys():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_message_vs_commit: List[Dict[str, str]] = []\n",
    "tmp_commits = set()\n",
    "\n",
    "for commit in filtered_predicted_messages.keys():\n",
    "    tmp_commits.add(commit)\n",
    "    one_message_vs_commit.append({\"commit\" : commit,\n",
    "                                  \"message\": leave_only_one_message_per_commit(filtered_predicted_messages[commit])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19036"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_message_vs_commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19036"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code2seq_commits_all & tmp_commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19036"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log_commits_all & tmp_commits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_out_file = \"/Users/natalia.murycheva/PycharmProjects/gitCommitMessageCollector/\" \\\n",
    "               \"naive_bayes/filtered.code2seq.result.csv\"\n",
    "\n",
    "csv_columns = [\"commit\", \"message\"]\n",
    "try:\n",
    "    with open(csv_out_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns, )\n",
    "        writer.writeheader()\n",
    "        for data in one_message_vs_commit:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = \"/Users/natalia.murycheva/Documents/\"\\\n",
    "      \"gitCommitMessageCollectorStorage/gcm_aurora_com_com_msg_author_date.log\"\n",
    "SEPARATOR = \"THIS_STRING_WILL_NEVER_APPEAR_IN_DATASET_AND_IT_WILL_BE_USED_AS_SEPARATOR\"\n",
    "\n",
    "log_commits_all = set()\n",
    "with open(log, 'r') as full_log_file:\n",
    "    for line in full_log_file:\n",
    "        if line.startswith(\"parent_commit_file_hash\"):\n",
    "            continue\n",
    "        i += 1\n",
    "        line_list = line.split(SEPARATOR)\n",
    "        commit, message = line_list[1], line_list[4]\n",
    "        log_commits_all.add(commit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19037"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code2seq_commits_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19037"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code2seq_commits_all & log_commits_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37077"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log_commits_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
