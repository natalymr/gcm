{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_header, tokens_header, message_header = \"cluster\", \"tokens\", \"message\"\n",
    "cluster1, cluster2, cluster3, cluster4, cluster5 = \"NoInfo\", \"Test\", \"Bomb\", \"Npe\", \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_data(input_file: str):\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    elements_to_delete = []\n",
    "    for each in data:\n",
    "        if each[message_header] == \"(no message)\":\n",
    "            elements_to_delete.append(each)\n",
    "    for e in elements_to_delete:\n",
    "        data.remove(e)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def cluster_all_messages(raw_data: List[Dict]) -> DataFrame:\n",
    "    result = []\n",
    "    deleted_tokens, added_tokens = \"deletedTokens\", \"addedTokens\"\n",
    "    for current in raw_data:\n",
    "        if \"cleanup\" in current[message_header] or \"minor\" in current[message_header] or \\\n",
    "            current[message_header] == \"fix\" or current[message_header] == \"fixes\" or \\\n",
    "            current[message_header] == \"several fixes\" or current[message_header] == \"minor fixes\" or \\\n",
    "            current[message_header] == \"yet another inference bug\" or \\\n",
    "            current[message_header] == \"some improvements (igor e. mikhailuk)\" or \\\n",
    "            current[message_header] == \"no changes actually\" or \\\n",
    "            current[message_header] == \"clean up\" or current[message_header] == \"cosmetics\":\n",
    "            \n",
    "            cluster = cluster1\n",
    " \n",
    "        elif \"test\" in current[message_header]:\n",
    "            cluster = cluster2\n",
    "        elif \"bomb\" in current[message_header]:\n",
    "            cluster = cluster3\n",
    "        elif \"npe\" in current[message_header] or \"null\" in current[message_header]:\n",
    "            cluster = cluster4\n",
    "        else:\n",
    "            cluster = cluster5\n",
    "        \n",
    "        if current[deleted_tokens]:  # list with tokens not empty\n",
    "            result.append({cluster_header: cluster,\n",
    "                           tokens_header: current[deleted_tokens],\n",
    "                           message_header: current[message_header]\n",
    "                           })\n",
    "        if current[added_tokens]:  # list with tokens not empty\n",
    "            result.append({cluster_header: cluster,\n",
    "                       tokens_header: current[added_tokens],\n",
    "                       message_header: current[message_header]\n",
    "                       })\n",
    "\n",
    "    return DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cluster                                            message  \\\n",
      "0        Other  don't retrieve method separators for binary fi...   \n",
      "1        Other  don't retrieve method separators for binary fi...   \n",
      "2        Other  force refresh properties on roots change (IDEA...   \n",
      "3        Other  force refresh properties on roots change (IDEA...   \n",
      "4       NoInfo                                            cleanup   \n",
      "5       NoInfo                                            cleanup   \n",
      "6       NoInfo                                            cleanup   \n",
      "7       NoInfo                                            cleanup   \n",
      "8       NoInfo                                            cleanup   \n",
      "9       NoInfo                                            cleanup   \n",
      "10      NoInfo                                            cleanup   \n",
      "11      NoInfo                                            cleanup   \n",
      "12       Other  avoid showing error twice on saving combobox p...   \n",
      "13       Other  avoid showing error twice on saving combobox p...   \n",
      "14       Other  avoid showing error twice on saving combobox p...   \n",
      "15       Other  avoid showing error twice on saving combobox p...   \n",
      "16       Other  avoid showing error twice on saving combobox p...   \n",
      "17       Other  avoid showing error twice on saving combobox p...   \n",
      "18       Other  avoid showing error twice on saving combobox p...   \n",
      "19       Other  avoid showing error twice on saving combobox p...   \n",
      "20       Other  avoid showing error twice on saving combobox p...   \n",
      "21       Other  avoid showing error twice on saving combobox p...   \n",
      "22       Other  avoid showing error twice on saving combobox p...   \n",
      "23       Other  avoid showing error twice on saving combobox p...   \n",
      "24       Other  avoid showing error twice on saving combobox p...   \n",
      "25       Other  avoid showing error twice on saving combobox p...   \n",
      "26       Other  avoid showing error twice on saving combobox p...   \n",
      "27       Other  allow to choose between inner and outer classe...   \n",
      "28       Other  allow to choose between inner and outer classe...   \n",
      "29       Other  allow to choose between inner and outer classe...   \n",
      "...        ...                                                ...   \n",
      "100996   Other                 merged CVS and Subversion versions   \n",
      "100997   Other                 merged CVS and Subversion versions   \n",
      "100998   Other                 merged CVS and Subversion versions   \n",
      "100999   Other                 merged CVS and Subversion versions   \n",
      "101000   Other                 merged CVS and Subversion versions   \n",
      "101001   Other                 merged CVS and Subversion versions   \n",
      "101002   Other                 merged CVS and Subversion versions   \n",
      "101003   Other                 merged CVS and Subversion versions   \n",
      "101004   Other                 merged CVS and Subversion versions   \n",
      "101005   Other                 merged CVS and Subversion versions   \n",
      "101006   Other                 merged CVS and Subversion versions   \n",
      "101007   Other                 merged CVS and Subversion versions   \n",
      "101008   Other                                          NPE fixed   \n",
      "101009   Other                                          NPE fixed   \n",
      "101010   Other                          replace paths with macros   \n",
      "101011     Npe                   fix npe - delete jdk from module   \n",
      "101012   Other      assign src and javadocs for internal idea jdk   \n",
      "101013   Other      assign src and javadocs for internal idea jdk   \n",
      "101014   Other                                      fix for MacOS   \n",
      "101015   Other                                      fix for MacOS   \n",
      "101016    Test                                               test   \n",
      "101017    Test                                               test   \n",
      "101018   Other                                add externalization   \n",
      "101019   Other                                add externalization   \n",
      "101020   Other                                         \"shift f1\"   \n",
      "101021   Other                             add checkConfiguration   \n",
      "101022   Other                                reverted back to 42   \n",
      "101023   Other                                reverted back to 42   \n",
      "101024   Other                                reverted back to 42   \n",
      "101025   Other                                reverted back to 42   \n",
      "\n",
      "                                                   tokens  \n",
      "0       [\\n\\n    , StringBuffer, openTag, new, StringB...  \n",
      "1       [org, jetbrains, annotations, NonNls, import, ...  \n",
      "2                                    [handleEvent, event]  \n",
      "3       [myRefreshPropertiesRequest, myRefreshProperti...  \n",
      "4                                                 [final]  \n",
      "5                    [getBody, body, method, \\n      , =]  \n",
      "6                                          [return, null]  \n",
      "7       [import, java, util, List, import, java, util,...  \n",
      "8       [isAllowOuterTargetClass, protected, boolean, ...  \n",
      "9       [import, org, jetbrains, annotations, NotNull,...  \n",
      "10      [isAllowOuterTargetClass, protected, boolean, ...  \n",
      "11      [getContainingClass, assertTrue, targetClass, ...  \n",
      "12                   [boolean, closeEditorOnError, final]  \n",
      "13      [boolean, closeEditorOnError, closeEditorOnErr...  \n",
      "14                   [boolean, closeEditorOnError, final]  \n",
      "15                   [final, boolean, closeEditorOnError]  \n",
      "16      [PsiClass, aClass, PsiMethod, setter, aClass, ...  \n",
      "17      [Ref, openapi, com, intellij, import, util, \\n...  \n",
      "18                                                [false]  \n",
      "19                                                [false]  \n",
      "20                                                [false]  \n",
      "21                                                 [true]  \n",
      "22                                                [false]  \n",
      "23                                                [false]  \n",
      "24                                                [false]  \n",
      "25                                         [false, false]  \n",
      "26                                                [false]  \n",
      "27      [isAllowOuterTargetClass, boolean, true, \\n   ...  \n",
      "28      [protected, boolean, isAllowOuterTargetClass, ...  \n",
      "29      [psi, PsiUtil, util, false, ref, ref, PsiRefer...  \n",
      "...                                                   ...  \n",
      "100996                                  [\\n    , private]  \n",
      "100997                                               [!=]  \n",
      "100998                                            [==, !]  \n",
      "100999                                               [!=]  \n",
      "101000                                        [equals, !]  \n",
      "101001  [PsiClass, lexicallyEnclosingClass, while, lex...  \n",
      "101002                               [classRef, classRef]  \n",
      "101003                               [location, location]  \n",
      "101004  [OverlyStringCastFix, OverlyStringCastFix, Ove...  \n",
      "101005  [OverlyStrongCastFix, OverlyStrongCastFix, Ove...  \n",
      "101006                                     [\\n\\n\\n, List]  \n",
      "101007  [\\n\\n, interface, TestInter, \\n\\n, ArrayList, ...  \n",
      "101008  [psi, codeStyle, CodeStyleManager, intellij, i...  \n",
      "101009  [PsiJavaToken, rbrace, getRBrace, rbrace, !=, ...  \n",
      "101010  [FileUtil, toSystemIndependentName, FileUtil, ...  \n",
      "101011                                [||, jdk, ==, null]  \n",
      "101012                                     [CLASS, CLASS]  \n",
      "101013                                  [JAVADOC, SOURCE]  \n",
      "101014  [VM_EXE_NAME, \"java\", final, static, private, ...  \n",
      "101015  [ \\n\\n  , jreHome, SystemInfo, isLinux, System...  \n",
      "101016  [com, intellij, openapi, vcs, VcsConfiguration...  \n",
      "101017  [getCommonSettings, getCommonSettings, getComm...  \n",
      "101018                                          [private]  \n",
      "101019  [com, intellij, openapi, util, JDOMExternaliza...  \n",
      "101020  [docFile, docFile, &&, docFile, isDirectory, L...  \n",
      "101021  [throw, RuntimeConfigurationException, \"Plugin...  \n",
      "101022  [import, com, intellij, openapi, roots, import...  \n",
      "101023  [\\n\\n, class, PluginModuleBuilder, extends, Ja...  \n",
      "101024  [      \\n, reateOutputPathPathsStep, nameAndLo...  \n",
      "101025  [createModuleBuilder, \\n    , return, new, Plu...  \n",
      "\n",
      "[101026 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "################### get data; IDEA ###################\n",
    "parent_dir = \"/Users/natalia.murycheva/Documents/gitCommitMessageCollectorStorage\"\n",
    "git_dir_name = \"intellij\"\n",
    "git_dir = os.path.join(parent_dir, git_dir_name)\n",
    "json_with_diffs = f\"{git_dir_name}_diff_blobs.json\"\n",
    "json_with_diffs = os.path.join(parent_dir, json_with_diffs)\n",
    "\n",
    "raw_data = load_and_filter_data(json_with_diffs)\n",
    "df = cluster_all_messages(raw_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total shape \t\t(101026, 3)\n",
      "size cluster1 \tNoInfo\t4025\t%3.9841228990556887\n",
      "size cluster2 \tTest\t3711\t%3.6733118207194186\n",
      "size cluster3 \tBomb\t421\t%0.4167244075782472\n",
      "size cluster4 \tNpe\t643\t%0.6364698196503871\n",
      "size cluster5 \tOther\t92226\t%91.28937105299626\n"
     ]
    }
   ],
   "source": [
    "print(f\"total shape \\t\\t{df.shape}\")\n",
    "\n",
    "total_size = df.shape[0]\n",
    "\n",
    "size1 = (df[cluster_header] == cluster1).sum()\n",
    "size2 = (df[cluster_header] == cluster2).sum()\n",
    "size3 = (df[cluster_header] == cluster3).sum()\n",
    "size4 = (df[cluster_header] == cluster4).sum()\n",
    "size5 = (df[cluster_header] == cluster5).sum()\n",
    "\n",
    "print(f\"size cluster1 \\t{cluster1}\\t{size1}\\t%{(size1/total_size)*100}\")\n",
    "print(f\"size cluster2 \\t{cluster2}\\t{size2}\\t%{(size2/total_size)*100}\")\n",
    "print(f\"size cluster3 \\t{cluster3}\\t{size3}\\t%{(size3/total_size)*100}\")\n",
    "print(f\"size cluster4 \\t{cluster4}\\t{size4}\\t%{(size4/total_size)*100}\")\n",
    "print(f\"size cluster5 \\t{cluster5}\\t{size5}\\t%{(size5/total_size)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### split data ###################\n",
    "\n",
    "msg_train , msg_test, y_train, y_test = train_test_split(df[message_header], df[cluster_header],\n",
    "                                                         test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(msg_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       1.00      0.20      0.33       123\n",
      "      NoInfo       0.97      0.76      0.85      1203\n",
      "         Npe       1.00      0.38      0.55       194\n",
      "       Other       0.97      1.00      0.99     27695\n",
      "        Test       0.90      0.71      0.79      1093\n",
      "\n",
      "    accuracy                           0.97     30308\n",
      "   macro avg       0.97      0.61      0.70     30308\n",
      "weighted avg       0.97      0.97      0.97     30308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################### classififcation results ###################\n",
    "predicted = text_clf.predict(msg_test)\n",
    "np.mean(predicted == y_test)    \n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = 0.22162699056501112\n"
     ]
    }
   ],
   "source": [
    "################### bleu score ###################\n",
    "total_score = 0.\n",
    "for msg, cluster in zip(msg_test, predicted):\n",
    "    if cluster == cluster1:\n",
    "        candidate = \"cleanup\"\n",
    "    elif cluster == cluster2:\n",
    "        candidate = \"test\"\n",
    "    elif cluster == cluster3:\n",
    "        candidate = \"bomb\"\n",
    "    elif cluster == cluster4:\n",
    "        candidate = \"npe\"\n",
    "    else:\n",
    "        candidate = \"smth was changed\"\n",
    "    \n",
    "    score = sentence_bleu([msg], candidate, weights=(1, 0, 0, 0))\n",
    "    total_score += score\n",
    "\n",
    "print(f\"Result = {total_score / len(msg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cluster                                            message  \\\n",
      "0         Test                                               test   \n",
      "1         Test                                               test   \n",
      "2        Other  This commit was manufactured by cvs2svn to cre...   \n",
      "3        Other  This commit was manufactured by cvs2svn to cre...   \n",
      "4        Other                                             import   \n",
      "5        Other                                             import   \n",
      "6         Test                                               test   \n",
      "7         Test                                               test   \n",
      "8        Other                                               init   \n",
      "9        Other                                               init   \n",
      "10       Other                                               init   \n",
      "11       Other                                No changes actually   \n",
      "12       Other                                No changes actually   \n",
      "13       Other                                No changes actually   \n",
      "14       Other             saving user templates in configuration   \n",
      "15       Other  fixing improper usage of optional debug API (l...   \n",
      "16       Other  fixing improper usage of optional debug API (l...   \n",
      "17       Other  setModel is called after init of myMemberInfoM...   \n",
      "18       Other  setModel is called after init of myMemberInfoM...   \n",
      "19       Other  fixes: sorting of resource bundle properties i...   \n",
      "20       Other  fixes: sorting of resource bundle properties i...   \n",
      "21       Other  fixes: sorting of resource bundle properties i...   \n",
      "22       Other  fixes: sorting of resource bundle properties i...   \n",
      "23       Other  fixes: sorting of resource bundle properties i...   \n",
      "24       Other        MacOS debugger/mousewheel bug worked around   \n",
      "25       Other                Opening page for tomcat 4.0.6 fixed   \n",
      "26       Other  OpenSource and 1-Year Educational license type...   \n",
      "27       Other  OpenSource and 1-Year Educational license type...   \n",
      "28       Other  OpenSource and 1-Year Educational license type...   \n",
      "29       Other  OpenSource and 1-Year Educational license type...   \n",
      "...        ...                                                ...   \n",
      "172293   Other                                     initial import   \n",
      "172294   Other                                     initial import   \n",
      "172295   Other                                     initial import   \n",
      "172296   Other                                     initial import   \n",
      "172297   Other                                     initial import   \n",
      "172298   Other                                     initial import   \n",
      "172299   Other                                     initial import   \n",
      "172300   Other                                     initial import   \n",
      "172301   Other                                     initial import   \n",
      "172302   Other                                     initial import   \n",
      "172303   Other                                     initial import   \n",
      "172304   Other                                     initial import   \n",
      "172305   Other                                     initial import   \n",
      "172306   Other                                     initial import   \n",
      "172307   Other                                     initial import   \n",
      "172308   Other                                     initial import   \n",
      "172309   Other                                    Two new getters   \n",
      "172310   Other                                    Two new getters   \n",
      "172311   Other                              Some fixes and update   \n",
      "172312   Other                              Some fixes and update   \n",
      "172313   Other                              Some fixes and update   \n",
      "172314   Other                              Some fixes and update   \n",
      "172315   Other                              Some fixes and update   \n",
      "172316   Other                              Some fixes and update   \n",
      "172317   Other                              Some fixes and update   \n",
      "172318   Other                              Some fixes and update   \n",
      "172319   Other                              Some fixes and update   \n",
      "172320   Other                              Some fixes and update   \n",
      "172321   Other                              Some fixes and update   \n",
      "172322   Other                              Some fixes and update   \n",
      "\n",
      "                                                   tokens  \n",
      "0       [/*\\n * Copyright (c) 2005 Your Corporation. A...  \n",
      "1       [/*\\nchanged\\n * Copyright (c) 2005 Your Corpo...  \n",
      "2       [/*\\n * Copyright (c) 2005 Your Corporation. A...  \n",
      "3       [package, jetbrains, buildServer, agent, ant, ...  \n",
      "4       [/*\\n * Copyright (c) 2005 Your Corporation. A...  \n",
      "5       [package, jetbrains, buildServer, agent, ant, ...  \n",
      "6       [/**\\n * Created by IntelliJ IDEA.\\n * User: l...  \n",
      "7       [/**\\n change\\n * Created by IntelliJ IDEA.\\n ...  \n",
      "8       [package, jetbrains, \\n\\n, import, com, sshtoo...  \n",
      "9       [package, jetbrains, \\n\\n, import, com, sshtoo...  \n",
      "10      [package, jetbrains, \\n\\n, import, com, sshtoo...  \n",
      "11             [\\n          , \\n          , \\n          ]  \n",
      "12                                                 [\\n\\n]  \n",
      "13                                                 [\\n\\n]  \n",
      "14      [ConfigurationManager, configurationManager, S...  \n",
      "15                                 [versionHigher, \"1.4\"]  \n",
      "16                                   [canRedefineClasses]  \n",
      "17                             [\\n\\n\\n\\n, \\n    , \\n    ]  \n",
      "18                             [\\n\\n, \\n\\n    , \\n\\n    ]  \n",
      "19                                    [replace, '.', '/']  \n",
      "20      [isVisibleFromClassLoader, isVisibleFromClassL...  \n",
      "21                                            [getSecond]  \n",
      "22                                             [getFirst]  \n",
      "23                                    [replace, '/', '.']  \n",
      "24                    [&&, !, instanceof, JFrame, window]  \n",
      "25      [final, String, text, !, isStartingMessage, te...  \n",
      "26      [\\n\\n  , boolean, isYearAcademic, \\n\\n  , bool...  \n",
      "27      [isOpenSource, OPENSOURCE, isYearAcademic, lic...  \n",
      "28      [\\n    , \\n    , \\n      , \\n    , \\n    , \\n ...  \n",
      "29      [OPENSOURCE, 3, final, =, final, YEARACADEMIC,...  \n",
      "...                                                   ...  \n",
      "172293  [// This software is subject to the terms of t...  \n",
      "172294  [// This software is subject to the terms of t...  \n",
      "172295  [// This software is subject to the terms of t...  \n",
      "172296  [// This software is subject to the terms of t...  \n",
      "172297  [// This software is subject to the terms of t...  \n",
      "172298  [// This software is subject to the terms of t...  \n",
      "172299  [// This software is subject to the terms of t...  \n",
      "172300  [// This software is subject to the terms of t...  \n",
      "172301  [// This software is subject to the terms of t...  \n",
      "172302  [// This software is subject to the terms of t...  \n",
      "172303  [// This software is subject to the terms of t...  \n",
      "172304  [// This software is subject to the terms of t...  \n",
      "172305  [// This software is subject to the terms of t...  \n",
      "172306  [// This software is subject to the terms of t...  \n",
      "172307  [// This software is subject to the terms of t...  \n",
      "172308  [// This software is subject to the terms of t...  \n",
      "172309  [package, com, intellij, codeInsight, completi...  \n",
      "172310  [package, com, intellij, codeInsight, completi...  \n",
      "172311  [\\n\\n, \\n\\n, \\n  , \\n\\n  , \\n    , \\n    , \\n ...  \n",
      "172312  [\\r\\n\\r\\n, \\r\\n, \\r\\n, \\r\\n, \\r\\n\\r\\n\\r\\n, \\r\\...  \n",
      "172313  [codeInsight, completion, filters, ThisOrAnyIn...  \n",
      "172314  [PsiElement, com, intellij, psi, import, PsiEl...  \n",
      "172315  [package, com, intellij, codeInsight, completi...  \n",
      "172316  [package, com, intellij, codeInsight, completi...  \n",
      "172317  [package, com, intellij, codeInsight, completi...  \n",
      "172318  [package, com, intellij, codeInsight, completi...  \n",
      "172319  [package, com, intellij, codeInsight, completi...  \n",
      "172320  [context, context, context, context, PsiElemen...  \n",
      "172321  [\\n\\n, \\n\\n, \\n\\n, /**\\n * Created by IntelliJ...  \n",
      "172322  [\\r\\n\\r\\n, \\r\\n, \\r\\n, \\r\\n, \\r\\n, \\r\\n, \\r\\n,...  \n",
      "\n",
      "[172323 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "################### get data; AURORA ###################\n",
    "parent_dir = \"/Users/natalia.murycheva/Documents/gitCommitMessageCollectorStorage\"\n",
    "git_dir_name = \"aurora\"\n",
    "git_dir = os.path.join(parent_dir, git_dir_name)\n",
    "json_with_diffs = f\"{git_dir_name}_diff_blobs.json\"\n",
    "json_with_diffs = os.path.join(parent_dir, json_with_diffs)\n",
    "\n",
    "raw_data = load_and_filter_data(json_with_diffs)\n",
    "aurora = cluster_all_messages(raw_data)\n",
    "print(aurora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total shape \t\t(172323, 3)\n",
      "size cluster1 \tNoInfo\t138\t%0.08008217127139151\n",
      "size cluster2 \tTest\t34255\t%19.878367948561714\n",
      "size cluster3 \tBomb\t60\t%0.03481833533538762\n",
      "size cluster4 \tNpe\t169\t%0.09807164452800844\n",
      "size cluster5 \tOther\t137701\t%79.9086599003035\n"
     ]
    }
   ],
   "source": [
    "print(f\"total shape \\t\\t{aurora.shape}\")\n",
    "\n",
    "total_size = aurora.shape[0]\n",
    "\n",
    "size1 = (aurora[cluster_header] == cluster1).sum()\n",
    "size2 = (aurora[cluster_header] == cluster2).sum()\n",
    "size3 = (aurora[cluster_header] == cluster3).sum()\n",
    "size4 = (aurora[cluster_header] == cluster4).sum()\n",
    "size5 = (aurora[cluster_header] == cluster5).sum()\n",
    "\n",
    "print(f\"size cluster1 \\t{cluster1}\\t{size1}\\t%{(size1/total_size)*100}\")\n",
    "print(f\"size cluster2 \\t{cluster2}\\t{size2}\\t%{(size2/total_size)*100}\")\n",
    "print(f\"size cluster3 \\t{cluster3}\\t{size3}\\t%{(size3/total_size)*100}\")\n",
    "print(f\"size cluster4 \\t{cluster4}\\t{size4}\\t%{(size4/total_size)*100}\")\n",
    "print(f\"size cluster5 \\t{cluster5}\\t{size5}\\t%{(size5/total_size)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### split data ###################\n",
    "\n",
    "a_msg_train , a_msg_test, a_y_train, a_y_test = train_test_split(aurora[message_header], aurora[cluster_header],\n",
    "                                                                 test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       0.00      0.00      0.00        20\n",
      "      NoInfo       0.94      0.71      0.81        41\n",
      "         Npe       1.00      0.02      0.04        48\n",
      "       Other       0.80      1.00      0.89     41234\n",
      "        Test       0.81      0.01      0.02     10354\n",
      "\n",
      "    accuracy                           0.80     51697\n",
      "   macro avg       0.71      0.35      0.35     51697\n",
      "weighted avg       0.80      0.80      0.71     51697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################### classififcation results ###################\n",
    "a_predicted = text_clf.predict(a_msg_test)\n",
    "np.mean(a_predicted == a_y_test)    \n",
    "print(metrics.classification_report(a_y_test, a_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = 0.030793871912447895\n"
     ]
    }
   ],
   "source": [
    "################### bleu score ###################\n",
    "total_score = 0.\n",
    "for msg, cluster in zip(a_msg_test, predicted):\n",
    "    if cluster == cluster1:\n",
    "        candidate = \"cleanup\"\n",
    "    elif cluster == cluster2:\n",
    "        candidate = \"test\"\n",
    "    elif cluster == cluster3:\n",
    "        candidate = \"bomb\"\n",
    "    elif cluster == cluster4:\n",
    "        candidate = \"npe\"\n",
    "    else:\n",
    "        candidate = \"smth was changed\"\n",
    "    \n",
    "    score = sentence_bleu([msg], candidate, weights=(1, 0, 0, 0))\n",
    "    total_score += score\n",
    "\n",
    "print(f\"Result = {total_score / len(a_msg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################### fit on aurora dataset ###################\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(a_msg_train, a_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       1.00      0.60      0.75        20\n",
      "      NoInfo       0.86      0.76      0.81        41\n",
      "         Npe       0.21      0.77      0.33        48\n",
      "       Other       1.00      1.00      1.00     41234\n",
      "        Test       1.00      0.98      0.99     10354\n",
      "\n",
      "    accuracy                           0.99     51697\n",
      "   macro avg       0.81      0.82      0.77     51697\n",
      "weighted avg       1.00      0.99      0.99     51697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################### classififcation results ###################\n",
    "a_predicted = text_clf.predict(a_msg_test)\n",
    "np.mean(a_predicted == a_y_test)    \n",
    "print(metrics.classification_report(a_y_test, a_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = 0.030793871912447895\n"
     ]
    }
   ],
   "source": [
    "################### bleu score ###################\n",
    "total_score = 0.\n",
    "for msg, cluster in zip(a_msg_test, predicted):\n",
    "    if cluster == cluster1:\n",
    "        candidate = \"cleanup\"\n",
    "    elif cluster == cluster2:\n",
    "        candidate = \"test\"\n",
    "    elif cluster == cluster3:\n",
    "        candidate = \"bomb\"\n",
    "    elif cluster == cluster4:\n",
    "        candidate = \"npe\"\n",
    "    else:\n",
    "        candidate = \"smth was changed\"\n",
    "    \n",
    "    score = sentence_bleu([msg], candidate, weights=(1, 0, 0, 0))\n",
    "    total_score += score\n",
    "\n",
    "print(f\"Result = {total_score / len(a_msg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################### fit on idea and then on aurora ###################\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(msg_train, y_train)\n",
    "text_clf.fit(a_msg_train, a_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bomb       1.00      0.60      0.75        20\n",
      "      NoInfo       0.86      0.76      0.81        41\n",
      "         Npe       0.21      0.77      0.33        48\n",
      "       Other       1.00      1.00      1.00     41234\n",
      "        Test       1.00      0.98      0.99     10354\n",
      "\n",
      "    accuracy                           0.99     51697\n",
      "   macro avg       0.81      0.82      0.77     51697\n",
      "weighted avg       1.00      0.99      0.99     51697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################### classififcation results ###################\n",
    "a_predicted = text_clf.predict(a_msg_test)\n",
    "np.mean(a_predicted == a_y_test)    \n",
    "print(metrics.classification_report(a_y_test, a_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = 0.030793871912447895\n"
     ]
    }
   ],
   "source": [
    "################### bleu score ###################\n",
    "total_score = 0.\n",
    "for msg, cluster in zip(a_msg_test, predicted):\n",
    "    if cluster == cluster1:\n",
    "        candidate = \"cleanup\"\n",
    "    elif cluster == cluster2:\n",
    "        candidate = \"test\"\n",
    "    elif cluster == cluster3:\n",
    "        candidate = \"bomb\"\n",
    "    elif cluster == cluster4:\n",
    "        candidate = \"npe\"\n",
    "    else:\n",
    "        candidate = \"smth was changed\"\n",
    "    \n",
    "    score = sentence_bleu([msg], candidate, weights=(1, 0, 0, 0))\n",
    "    total_score += score\n",
    "\n",
    "print(f\"Result = {total_score / len(a_msg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = 0.03071389456281856\n"
     ]
    }
   ],
   "source": [
    "################### bleu score; change cluster1 ###################\n",
    "total_score = 0.\n",
    "for msg, cluster in zip(a_msg_test, predicted):\n",
    "    if cluster == cluster1:\n",
    "        candidate = \"fix\"\n",
    "    elif cluster == cluster2:\n",
    "        candidate = \"test\"\n",
    "    elif cluster == cluster3:\n",
    "        candidate = \"bomb\"\n",
    "    elif cluster == cluster4:\n",
    "        candidate = \"npe\"\n",
    "    else:\n",
    "        candidate = \"smth was changed\"\n",
    "    \n",
    "    score = sentence_bleu([msg], candidate, weights=(1, 0, 0, 0))\n",
    "    total_score += score\n",
    "\n",
    "print(f\"Result = {total_score / len(a_msg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
